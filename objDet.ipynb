{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf22878-09d5-4f48-881b-420218fd5756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "396a3eb6-de6e-4626-a33b-3729148de0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOTrainerDetector:\n",
    "    def __init__(self):\n",
    "        self.img_size = 640\n",
    "        self.conf_thresh = 0.25\n",
    "        self.epochs = 50\n",
    "        self.batch_size = 16\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(self.device)\n",
    "        \n",
    "    def prepare_data(self, annotations_path, data_dir):\n",
    "        \"\"\"Prepare dataset from CSV annotations file with format:\n",
    "        filename,width,height,xmin,ymin,xmax,ymax,class\n",
    "        \"\"\"\n",
    "        # Create directories\n",
    "        os.makedirs('dataset/images/train', exist_ok=True)\n",
    "        os.makedirs('dataset/images/val', exist_ok=True)\n",
    "        os.makedirs('dataset/labels/train', exist_ok=True)\n",
    "        os.makedirs('dataset/labels/val', exist_ok=True)\n",
    "        \n",
    "        # Read annotations\n",
    "        df = pd.read_csv(annotations_path)\n",
    "        \n",
    "        # Extract unique class names and create mapping\n",
    "        unique_classes = sorted(df['class'].unique())\n",
    "        class_dict = {class_name: i for i, class_name in enumerate(unique_classes)}\n",
    "        \n",
    "        print(f\"Found {len(unique_classes)} classes: {unique_classes}\")\n",
    "        print(f\"Class mapping: {class_dict}\")\n",
    "        \n",
    "        # Create YAML config file for YOLOv8\n",
    "        data_yaml = {\n",
    "            'path': os.path.abspath('dataset'),\n",
    "            'train': 'images/train',\n",
    "            'val': 'images/val',\n",
    "            'names': {i: name for i, name in enumerate(unique_classes)}\n",
    "        }\n",
    "        \n",
    "        with open('dataset/data.yaml', 'w') as f:\n",
    "            yaml.dump(data_yaml, f, sort_keys=False)\n",
    "        \n",
    "        # Group by image\n",
    "        image_groups = df.groupby('filename')\n",
    "        \n",
    "        # Split into train (80%) and validation (20%) sets\n",
    "        image_paths = list(image_groups.groups.keys())\n",
    "        split_idx = int(len(image_paths) * 0.8)\n",
    "        train_images = image_paths[:split_idx]\n",
    "        val_images = image_paths[split_idx:]\n",
    "        \n",
    "        # Process each image and its annotations\n",
    "        for img_path in train_images:\n",
    "            self.process_image(img_path, image_groups, data_dir, 'train', class_dict)\n",
    "        \n",
    "        for img_path in val_images:\n",
    "            self.process_image(img_path, image_groups, data_dir, 'val', class_dict)\n",
    "        \n",
    "        print(f\"Dataset prepared with {len(train_images)} training and {len(val_images)} validation images\")\n",
    "        return 'dataset/data.yaml'\n",
    "\n",
    "    def process_image(self, img_path, image_groups, data_dir, split, class_dict):\n",
    "        \"\"\"Process a single image and its annotations\"\"\"\n",
    "        # Get annotations for this image\n",
    "        annotations = image_groups.get_group(img_path)\n",
    "        \n",
    "        # Copy image to dataset\n",
    "        img_src = os.path.join(data_dir, img_path)\n",
    "        img_dst = os.path.join('dataset/images', split, img_path)\n",
    "        \n",
    "        # Skip if image doesn't exist\n",
    "        if not os.path.exists(img_src):\n",
    "            print(f\"Warning: Image {img_src} not found, skipping\")\n",
    "            return\n",
    "        \n",
    "        # Copy image\n",
    "        img = Image.open(img_src)\n",
    "        os.makedirs(os.path.dirname(img_dst), exist_ok=True)\n",
    "        img.save(img_dst)\n",
    "        \n",
    "        # Get image dimensions from CSV\n",
    "        img_width = annotations['width'].iloc[0]\n",
    "        img_height = annotations['height'].iloc[0]\n",
    "        \n",
    "        # Create label file (YOLO format: class x_center y_center width height)\n",
    "        label_path = os.path.join('dataset/labels', split, os.path.splitext(img_path)[0] + '.txt')\n",
    "        os.makedirs(os.path.dirname(label_path), exist_ok=True)\n",
    "        \n",
    "        with open(label_path, 'w') as f:\n",
    "            for _, row in annotations.iterrows():\n",
    "                # Get class ID from the class column\n",
    "                class_name = row['class']\n",
    "                class_id = class_dict[class_name]\n",
    "                \n",
    "                # Convert bbox coordinates to YOLO format\n",
    "                x_min, y_min, x_max, y_max = row['xmin'], row['ymin'], row['xmax'], row['ymax']\n",
    "                \n",
    "                # Normalize to 0-1\n",
    "                x_center = ((x_min + x_max) / 2) / img_width\n",
    "                y_center = ((y_min + y_max) / 2) / img_height\n",
    "                bbox_width = (x_max - x_min) / img_width\n",
    "                bbox_height = (y_max - y_min) / img_height\n",
    "                \n",
    "                # Write to file\n",
    "                f.write(f\"{class_id} {x_center} {y_center} {bbox_width} {bbox_height}\\n\")\n",
    "\n",
    "    def train_model(self, data_yaml, weights='yolov8n.pt'):\n",
    "        model = YOLO(weights).to(self.device)\n",
    "        \n",
    "        results = model.train(\n",
    "            data=data_yaml,\n",
    "            epochs=self.epochs,\n",
    "            batch=self.batch_size,\n",
    "            imgsz=self.img_size,\n",
    "            patience=10,\n",
    "            save=True,\n",
    "            device=self.device\n",
    "        )\n",
    "        \n",
    "        best_weights = results.best\n",
    "        print(f\"Training completed. Best weights saved to: {best_weights}\")\n",
    "        return best_weights\n",
    "\n",
    "    def detect_obstacles(self, model_path, image_path):\n",
    "        \n",
    "        model = YOLO(model_path).to(self.device)\n",
    "        \n",
    "        results = model.predict(\n",
    "            source=image_path,\n",
    "            conf=self.conf_thresh,\n",
    "            imgsz=self.img_size,\n",
    "            save=False,\n",
    "            device=self.device\n",
    "        )\n",
    "        \n",
    "        # Load image for visualization\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        # Process results\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            \n",
    "            for box in boxes:\n",
    "                # Get box coordinates\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "                conf = float(box.conf[0].cpu().numpy())\n",
    "                cls_id = int(box.cls[0].cpu().numpy())\n",
    "                cls_name = result.names[cls_id]\n",
    "                \n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Add label\n",
    "                label = f\"{cls_name}: {conf:.2f}\"\n",
    "                cv2.putText(img, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "        # Save and display the result\n",
    "        output_path = os.path.splitext(image_path)[0] + '_detected.jpg'\n",
    "        cv2.imwrite(output_path, img)\n",
    "        \n",
    "        # Display image\n",
    "        cv2.imshow('Obstacle Detection', img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"Detection results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b719f11-7e6f-4088-ba6a-0fe9c27a7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage - modify these paths as needed\n",
    "if __name__ == \"__main__\":\n",
    "    # CONFIGURATION: Update these paths for your use case\n",
    "    \n",
    "    # Mode - set to either \"train\" or \"detect\"\n",
    "    MODE = \"train\"  # Change to \"detect\" for inference\n",
    "    \n",
    "    # Training settings\n",
    "    ANNOTATIONS_PATH = \"data/export/annotations.csv\"  # Path to your CSV file\n",
    "    DATA_DIR = \"data/export/\"  # Directory containing your images\n",
    "    \n",
    "    # Detection settings\n",
    "    MODEL_WEIGHTS = \"yolov8n.pt\"  # For training: use pre-trained weights, for detection: use your trained weights\n",
    "    IMAGE_PATH = \"data/export/1478898901028431352_jpg.rf.bf49a488aeeba9b30e5b0455a1c0e100.jpg\"  # Image for detection\n",
    "    \n",
    "    # Create detector object\n",
    "    yolo = YOLOTrainerDetector()\n",
    "    \n",
    "    # Set custom parameters if needed\n",
    "    yolo.epochs = 10  # Number of training epochs\n",
    "    yolo.batch_size = 8  # Batch size\n",
    "    yolo.img_size = 640  # Image size\n",
    "    yolo.conf_thresh = 0.25  # Confidence threshold for detection\n",
    "    \n",
    "    # Run in selected mode\n",
    "    if MODE == \"train\":\n",
    "        # Prepare dataset and train model\n",
    "        data_yaml = yolo.prepare_data(ANNOTATIONS_PATH, DATA_DIR)\n",
    "        best_weights = yolo.train_model(data_yaml, weights=MODEL_WEIGHTS)\n",
    "        print(f\"Use the following weights for detection: {best_weights}\")\n",
    "    \n",
    "    elif MODE == \"detect\":\n",
    "        # Run detection\n",
    "        yolo.detect_obstacles(best_weights, IMAGE_PATH)\n",
    "    \n",
    "    else:\n",
    "        print(f\"Invalid mode: {MODE}. Use 'train' or 'detect'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57f36970-6115-4963-9cfd-13221a934f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=YOLO(\"runs/detect/train/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "410562b1-f66f-4a57-8de9-2e47099d4469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "\n",
      "image 1/1 D:\\minie\\code\\000010_10.png: 224x640 3 cars, 1 trafficLight-Red, 252.7ms\n",
      "Speed: 8.2ms preprocess, 252.7ms inference, 525.5ms postprocess per image at shape (1, 3, 224, 640)\n",
      "vanten\n",
      "vanten\n",
      "vanten\n",
      "vanten\n",
      "Detection results saved to 000010_10_detected.jpg\n"
     ]
    }
   ],
   "source": [
    "MODE = 'detect'\n",
    "yolo = YOLOTrainerDetector()\n",
    "yolo.detect_obstacles(\"runs/detect/train/weights/best.pt\", \"000010_10.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3966c708-3a4d-43db-9807-e63c324f090e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
